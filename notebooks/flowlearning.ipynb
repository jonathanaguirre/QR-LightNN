{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "7f3d5375-b1ca-47bd-8e53-156e7d8d1e63",
      "cell_type": "markdown",
      "source": "# Install",
      "metadata": {}
    },
    {
      "id": "c4f04192-a00b-46aa-8f34-ccc5f012a8cd",
      "cell_type": "code",
      "source": "%pip install qrcode[pil] Pillow tqdm",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "f71a520c-5326-40c6-be6d-19e42b661d1d",
      "cell_type": "markdown",
      "source": "# Import",
      "metadata": {}
    },
    {
      "id": "df6c85d9-9d09-4b03-92b5-45ab6120a770",
      "cell_type": "code",
      "source": "import os\nimport csv\nimport random\nimport uuid\nimport math\nimport numpy as np\nimport qrcode\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm import tqdm",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "id": "0794d972-fd4d-4340-a22a-041054c0017f",
      "cell_type": "markdown",
      "source": "# Create\n## A set of QR codes become a control group",
      "metadata": {}
    },
    {
      "id": "7fa9f92d-c12f-40da-8342-53860b6c24f7",
      "cell_type": "code",
      "source": "# Directories for QR codes\npng_dir = \"data/png\"\nos.makedirs(png_dir, exist_ok=True)\n\n# Candidate character set (digits 0-9)\ncharacter_set = list(\"0123456789\")\n\ndef generate_qr_png(data, file_path, version=1, error_correction=qrcode.constants.ERROR_CORRECT_L, box_size=10, border=4):\n    qr = qrcode.QRCode(\n        version=version,\n        error_correction=error_correction,\n        box_size=box_size,\n        border=border,\n    )\n    qr.add_data(data)\n    qr.make(fit=True)\n    img = qr.make_image(fill_color=\"black\", back_color=\"white\")\n    img.save(file_path)\n\n# Generate QR codes with progress\nprint(\"Generating QR codes...\")\nfor char in tqdm(character_set, desc=\"QR Codes\"):\n    png_path = os.path.join(png_dir, f\"{char}.png\")\n    generate_qr_png(char, png_path)\n\n# Show file sizes\nprint(\"\\nFile sizes for PNG QR codes:\")\nfor char in character_set:\n    png_path = os.path.join(png_dir, f\"{char}.png\")\n    size = os.path.getsize(png_path)\n    print(f\"{char}.png: {size} bytes\")\n\n# Define metadata path\nmetadata = \"data/metadata.csv\"\n\n# Create metadata CSV\nfiles = [f for f in os.listdir(png_dir) if f.endswith('.png')]\nwith open(metadata, 'w', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow([\"filename\", \"label\", \"filesize (Bytes)\"])\n    for f in tqdm(files, desc=\"Creating metadata\"):\n        label = os.path.splitext(f)[0]\n        file_path = os.path.join(png_dir, f)\n        filesize = os.path.getsize(file_path)\n        writer.writerow([file_path, label, filesize])\nprint(f\"\\nMetadata file created at {metadata}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Generating QR codes...\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "<ipython-input-3-d39b2fb2b277>:22: TqdmMonitorWarning: tqdm:disabling monitor support (monitor_interval = 0) due to:\ncan't start new thread\n  for char in tqdm(character_set, desc=\"QR Codes\"):\nQR Codes: 100%|██████████| 10/10 [00:02<00:00,  3.98it/s]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nFile sizes for PNG QR codes:\n0.png: 439 bytes\n1.png: 423 bytes\n2.png: 441 bytes\n3.png: 451 bytes\n4.png: 442 bytes\n5.png: 445 bytes\n6.png: 439 bytes\n7.png: 444 bytes\n8.png: 432 bytes\n9.png: 444 bytes\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Creating metadata: 100%|██████████| 10/10 [00:00<00:00, 59.88it/s]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nMetadata file created at data/metadata.csv\n"
        }
      ],
      "execution_count": 3
    },
    {
      "id": "1d1ae92c-fd01-4a12-abc4-4d809398bb2b",
      "cell_type": "markdown",
      "source": "# Create\n## Two distortions per image, becoming a test group.",
      "metadata": {}
    },
    {
      "id": "0ca07ec3-5db1-460a-8161-aeef9114c510",
      "cell_type": "code",
      "source": "# Augmentation setup\naugmented_dir = \"data/augmented\"\nos.makedirs(augmented_dir, exist_ok=True)\n\nROTATION_RANGE = (-10, 10)\nTRANSLATION_RANGE = (-5, 5)\nSCALING_RANGE = (0.9, 1.1)\nSHEAR_RANGE = (-10, 10)\n\ndef get_affine_matrix(rotation, tx, ty, scaling, shear, center):\n    theta = math.radians(rotation)\n    shear_rad = math.radians(shear)\n    R = np.array([\n        [math.cos(theta), -math.sin(theta)],\n        [math.sin(theta),  math.cos(theta)]\n    ])\n    S = np.array([\n        [scaling, 0],\n        [0, scaling]\n    ])\n    Sh = np.array([\n        [1, math.tan(shear_rad)],\n        [0, 1]\n    ])\n    A = R.dot(S).dot(Sh)\n    cx, cy = center\n    T = np.array([cx, cy]) - A.dot(np.array([cx, cy])) + np.array([tx, ty])\n    a, b = A[0, 0], A[0, 1]\n    d, e = A[1, 0], A[1, 1]\n    c, f = T[0], T[1]\n    return (a, b, c, d, e, f)\n    \nnum_augmentations = 2\naug_log_file = \"data/augmented_log.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "id": "68e66598-3c6f-4614-a7f2-886ed97a211d",
      "cell_type": "markdown",
      "source": "# Create\n## The test group metadata file is created",
      "metadata": {}
    },
    {
      "id": "0bd1d8ed-abc5-447e-9226-e9c33c77d6cb",
      "cell_type": "code",
      "source": "# Read metadata\ndf = pd.read_csv(metadata)\norig_image_paths = df['filename'].tolist()\norig_labels = df['label'].tolist()\n\nwith open(aug_log_file, 'w', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow([\"augmented_filename\", \"orig_filename\", \"orig_label\", \"rotation\", \"tx\", \"ty\", \"scaling\", \"shear\"])\n    \n    for orig_path, label in tqdm(zip(orig_image_paths, orig_labels), total=len(orig_image_paths), desc=\"Augmenting\"):\n        orig_basename = os.path.basename(orig_path)\n        img = Image.open(orig_path).convert(\"L\")\n        center = (img.size[0] / 2, img.size[1] / 2)\n        \n        for i in tqdm(range(num_augmentations), desc=f\"{label}.png\", leave=False):\n            rotation = random.uniform(*ROTATION_RANGE)\n            tx = random.uniform(*TRANSLATION_RANGE)\n            ty = random.uniform(*TRANSLATION_RANGE)\n            scaling = random.uniform(*SCALING_RANGE)\n            shear = random.uniform(*SHEAR_RANGE)\n            \n            matrix = get_affine_matrix(rotation, tx, ty, scaling, shear, center)\n            augmented_img = img.transform(img.size, Image.AFFINE, matrix, resample=Image.BICUBIC)\n            aug_filename = f\"{os.path.splitext(orig_basename)[0]}_aug_{i}.png\"\n            aug_filepath = os.path.join(augmented_dir, aug_filename)\n            augmented_img.save(aug_filepath)\n            writer.writerow([aug_filename, orig_basename, label, rotation, tx, ty, scaling, shear])\n\nprint(\"\\nAugmented images saved and CSV log written.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Augmenting:   0%|          | 0/10 [00:00<?, ?it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  1.31it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:01<00:00,  2.18it/s]\nAugmenting:  10%|█         | 1/10 [00:01<00:10,  1.15s/it]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  4.72it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  4.87it/s]\nAugmenting:  20%|██        | 2/10 [00:01<00:06,  1.20it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  5.59it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  4.72it/s]\nAugmenting:  30%|███       | 3/10 [00:02<00:05,  1.39it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  4.57it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  4.36it/s]\nAugmenting:  40%|████      | 4/10 [00:02<00:04,  1.47it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  4.69it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  4.30it/s]\nAugmenting:  50%|█████     | 5/10 [00:03<00:03,  1.49it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  3.85it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  4.08it/s]\nAugmenting:  60%|██████    | 6/10 [00:04<00:02,  1.46it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  3.51it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  3.64it/s]\nAugmenting:  70%|███████   | 7/10 [00:05<00:02,  1.40it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  2.96it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  3.18it/s]\nAugmenting:  80%|████████  | 8/10 [00:05<00:01,  1.31it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  3.03it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  3.18it/s]\nAugmenting:  90%|█████████ | 9/10 [00:06<00:00,  1.27it/s]\n\u001b[Ang:   0%|          | 0/2 [00:00<?, ?it/s]\n\u001b[Ang:  50%|█████     | 1/2 [00:00<00:00,  2.76it/s]\n\u001b[Ang: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\nAugmenting: 100%|██████████| 10/10 [00:07<00:00,  1.27it/s]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nAugmented images saved and CSV log written.\n"
        }
      ],
      "execution_count": 5
    },
    {
      "id": "0ed6843e-591a-440d-9f95-44c20dac06a5",
      "cell_type": "markdown",
      "source": "# Calculate\n## Distorted files are counted with their average sizes for reference",
      "metadata": {}
    },
    {
      "id": "5bf55bf3-48ae-4bf1-b76e-52efd9e2b786",
      "cell_type": "code",
      "source": "# Calculate average augmented image size\nprint(\"\\nCalculating average file size for Augmented images...\")\naug_files = [f for f in os.listdir(augmented_dir) if f.endswith('.png')]\ntotal_size = 0\nfor f in tqdm(aug_files, desc=\"File Size Calc\"):\n    file_path = os.path.join(augmented_dir, f)\n    total_size += os.path.getsize(file_path)\n\nif aug_files:\n    avg_size = total_size / len(aug_files)\n    print(f\"Total distortions files: {len(aug_files)}\")\n    print(f\"Average file size: {avg_size:.2f} bytes\")\nelse:\n    print(\"No Augmented PNG files found in the directory.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nCalculating average file size for Augmented images...\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "File Size Calc: 100%|██████████| 20/20 [00:00<00:00, 60.61it/s]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Total distortions files: 20\nAverage file size: 8125.15 bytes\n"
        }
      ],
      "execution_count": 6
    },
    {
      "id": "9850d16c-a5ac-4275-a346-700de26ad73a",
      "cell_type": "raw",
      "source": "This project is designed for flow-through learning, meaning little to no interruptions or stop-and-save moments.\nRationale being that Student notebooks should respect attention and momentum, thus no zipped project files\nare provided.",
      "metadata": {}
    }
  ]
}